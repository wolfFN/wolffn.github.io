《这就是 ChatGPT》

斯蒂芬·沃尔弗拉姆
21 个笔记

导读序 奇事·奇人·奇书

◆ 1991 年，沃尔弗拉姆又返回研究状态，开始“昼伏夜出”，每天深夜埋头做实验、写作长达十年，出版了 1000 多页的巨著《一种新科学》（A New Kind of Science）。书中的主要观点是：万事皆计算，宇宙中的各种复杂现象，不论是人产生的还是自然中自发的，都可以用一些规则简单地计算和模拟。

它只是一次添加一个词

◆ ChatGPT 从根本上始终要做的是，针对它得到的任何文本产生“合理的延续”。这里所说的“合理”是指，“人们在看到诸如数十亿个网页上的内容后，可能期待别人会这样写”。

◆ 值得注意的是，当 ChatGPT 做一些事情，比如写一篇文章时，它实质上只是在一遍又一遍地询问“根据目前的文本，下一个词应该是什么”，并且每次都添加一个词。［正如我将要解释的那样，更准确地说，它是每次都添加一个“标记”（token），而标记可能只是词的一部分。这就是它有时可以“造词”的原因。］

◆ 如果有时（随机）选择排名较低的词，就会得到一篇“更有趣”的文章。

◆ 这里存在随机性意味着，如果我们多次使用相同的提示（prompt），每次都有可能得到不同的文章。而且，符合玄学思想的是，有一个所谓的“温度”参数来确定低排名词的使用频率。对于文章生成来说，“温度”为 0.8 似乎最好。

神经网络训练的实践和学问

◆ 这门学问有几个关键部分。首先是针对特定的任务使用何种神经网络架构的问题。然后是如何获取用于训练神经网络的数据的关键问题。

◆ 后来发现，（至少对于“类人任务”）最好的方法通常是尝试训练神经网络来“解决端到端的问题”，让它自己“发现”必要的中间特征、编码等。

◆ 神经网络的实际学习过程是怎样的呢？归根结底，核心在于确定哪些权重能够最好地捕捉给定的训练样例。

◆ 结论是，训练神经网络很难，并且需要大量的计算工作。实际上，绝大部分工作是在处理数的数组，这正是 GPU 擅长的—这也是为什么神经网络训练通常受限于可用的 GPU 数量。

“足够大的神经网络当然无所不能！”

◆ 能力和可训练性之间存在着一个终极权衡：你越想让一个系统“真正利用”其计算能力，它就越会表现出计算不可约性，从而越不容易被训练；而它在本质上越易于训练，就越不能进行复杂的计算。

“嵌入”的概念

◆ 我们可以将词嵌入视为试图在一种“意义空间”中布局词，其中“在意义上相近”的词会出现在相近的位置。

◆ ChatGPT 内部就是这样进行处理的。它会获取到目前为止的所有文本，并生成一个嵌入向量来表示它。然后，它的目标就是找到下一个可能出现的各个词的概率。

◆ 严格来说，ChatGPT 并不处理词，而是处理“标记”（token）—这是一种方便的语言单位，既可以是整个词，也可以只是像 pre、ing 或 ized 这样的片段。使用标记使 ChatGPT 更容易处理罕见词、复合词和非英语词，并且会发明新单词（不论结果好坏）。

意义空间和语义运动定律

◆ 至少可以将这个特征空间视为将“意思相近的词”放在这个空间中的相近位置。

语义语法和计算语言的力量

◆ 人类语言是不精确的，这主要是因为它没有与特定的计算实现相“结合”，其意义基本上只由其使用者之间的“社会契约”定义。但是，计算语言在本质上具有一定的精确性，因为它指定的内容最终总是可以“在计算机上毫无歧义地执行”。

◆ 如何确定适用于一般符号话语语言的“本体论”（ontology）呢？这并不容易。也许这就是自亚里士多德 2000 多年前对本体论做出原始论述以来，在这些方面几乎没有什么进展的原因。

◆ 当谈到语义语法时，我们可以将其类比于三段论逻辑。最初，三段论逻辑本质上是关于用人类语言所表达的陈述的一组规则。但是，当形式逻辑被发展出来时（没错，在 2000 多年之后），三段论逻辑最初的基本结构也可以用来构建巨大的“形式化高塔”，能用于解释（比如）现代数字电路的运作。因此，我们可以期待更通用的语义语法也会如此。起初，它可能只能处理简单的模式，例如文本。但是，一旦它的整体计算语言框架被建立起来，我们就可以期待用它来搭建“广义语义逻辑”的高塔，让我们能够以精确和形式化的方式处理以前接触不到的各种事物（相比之下，我们现在只能在“地面层”处理人类语言，而且带有很大的模糊性）。

那么，ChatGPT 到底在做什么？它为什么能做到这些？

◆ ChatGPT 的基本概念在某种程度上相当简单：首先从互联网、书籍等获取人类创造的海量文本样本，然后训练一个神经网络来生成“与之类似”的文本。特别是，它能够从“提示”开始，继续生成“与其训练数据相似的文本”。

前方的路

◆ 虽然“原始 ChatGPT”可以在许多情况下帮助人们写作、提供建议或生成对各种文档或交流有用的文本，但是当必须把事情做到完美时，机器学习并不是解决问题的方法—就像人类也不是一样。

◆ 这正是我们在以上例子中看到的。ChatGPT 在“类人的部分”表现出色，因为其中没有精确的“正确答案”。但当它被“赶鸭子上架”、需要提供精确的内容时，往往会失败。这些例子要表达的重点是，有一种很好的方法可以解决该问题—将 ChatGPT 连接到 Wolfram|Alpha 以利用其全部的计算知识“超能力”。 在 Wolfram|Alpha 内部，一切都被转换为计算语言，转换为精确的 Wolfram 语言代码。这些代码在某种程度上必须是“完美”的，才能可靠地使用。

◆ 在许多方面，可以说 ChatGPT 从未“真正理解”过事物，它只“知道如何产生有用的东西”。但是 Wolfram|Alpha 则完全不同。因为一旦 Wolfram|Alpha 将某些东西转换为 Wolfram 语言，我们就拥有了它们完整、精确、形式化的表示，可以用来可靠地计算事物。

-- 来自微信读书
